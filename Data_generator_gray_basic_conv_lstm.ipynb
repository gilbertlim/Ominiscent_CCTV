{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-treat",
   "metadata": {},
   "source": [
    "# 1. VideoFrameGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-madness",
   "metadata": {},
   "source": [
    "#### Class(Fixed)\n",
    "- Normal : 150\n",
    "- Arson (+ Explosion) : 50 + 50 = 100\n",
    "- Assault (+ Abuse, Fighting) : 50 + 50 + 50 = 150\n",
    "- Burglary : 100\n",
    "\n",
    "#### Image Size(Fixed)\n",
    "- 128 X 128\n",
    "\n",
    "#### \\# of Frames(Fixed)\n",
    "- 64\n",
    "\n",
    "#### Data Split(Fixed)\n",
    "- 7 : 2 : 1\n",
    "\n",
    "#### Color Scale\n",
    "- **Gray** or RGB\n",
    "\n",
    "#### Frame Generator\n",
    "- **Basic** or Sliding or OpticalFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-invasion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODELNAME='g_basic_conv_lstm'\n",
    "\n",
    "SIZE = (128, 128)\n",
    "CHANNELS = 1 # Gray scale\n",
    "NBFRAME = 64 \n",
    "BS = 16\n",
    "SHUFFLE = True\n",
    "\n",
    "SPLIT_RATIO = (.2, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optimum-division",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Arson, validation count: 20, test count: 8, train count: 72\n",
      "class Assault, validation count: 30, test count: 12, train count: 108\n",
      "class Burglary, validation count: 20, test count: 8, train count: 72\n",
      "class Normal_Videos-Part-1, validation count: 30, test count: 12, train count: 108\n",
      "Total data: 4 classes for 360 files for train\n",
      "Total data: 4 classes for 100 files for validation\n",
      "Total data: 4 classes for 40 files for test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras\n",
    "\n",
    "from keras_video import VideoFrameGenerator\n",
    "\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('zip_integrate/*')]\n",
    "classes.sort()\n",
    "\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='zip_integrate/{classname}/*.mp4'\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, # class list\n",
    "    glob_pattern=glob_pattern, # directory path\n",
    "    nb_frames=NBFRAME, # #of frames to return for each sequence\n",
    "    rescale=1/255., # normalization\n",
    "    split_val=SPLIT_RATIO[0], # split validation\n",
    "    split_test=SPLIT_RATIO[1], # split test\n",
    "    shuffle=SHUFFLE, # randomize\n",
    "    batch_size=BS, # batch size\n",
    "    target_shape=SIZE, # image size\n",
    "    nb_channel=CHANNELS, # gray scale\n",
    "    transformation=data_aug, # data augmentation\n",
    "    use_frame_cache=False) # not save original frame\n",
    "    \n",
    "valid = train.get_validation_generator()\n",
    "test = train.get_test_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "champion-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_video.utils\n",
    "\n",
    "# keras_video.utils.show_sample(test, index=0, random=False, row_width=10, row_height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-composition",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-parcel",
   "metadata": {},
   "source": [
    "#### Conv2D + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "endless-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "def build_convnet(shape=SIZE + (CHANNELS,)):\n",
    "    momentum = .9\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=shape, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    # flatten...\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "superb-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout, LSTM\n",
    "\n",
    "def action_model(shape=(NBFRAME,) + SIZE + (CHANNELS,), nbout=len(classes)):\n",
    "    # Create our convnet with (128, 128, 1) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # add the convnet with (64, 128, 128, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "    \n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(LSTM(64))\n",
    "    \n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "south-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 64, 512)           1553664   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                147712    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,366,916\n",
      "Trainable params: 2,364,996\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (64, 128, 128, 3)\n",
    "\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "united-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer,\n",
    "              'categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simple-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "\n",
    "callbacks = [keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "             keras.callbacks.ModelCheckpoint(\n",
    "             'chkp/weights_' + MODELNAME + '_.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "             verbose=1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-antarctica",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist_model = model.fit(train,\n",
    "             validation_data=valid,\n",
    "             verbose=1,\n",
    "             epochs=EPOCHS,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(hist_model.history['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(epochs, hist_model.history['loss'])\n",
    "plt.plot(epochs, hist_model.history['val_loss'])\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(hist_model.history['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(epochs, hist_model.history['accuracy'])\n",
    "plt.plot(epochs, hist_model.history['val_accuracy'])\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "\n",
    "print('Loss = {:.5f}'.format(loss))\n",
    "print('Accuracy = {:.5f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'Models'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "final_model_name = '/' + MODELNAME + '.h5'\n",
    "\n",
    "model.save(save_dir + final_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lmn = load_model(save_dir + final_model_name)\n",
    "\n",
    "loss, accuracy = lmn.evaluate(test)\n",
    "\n",
    "print('Loss = {:.5f}'.format(loss))\n",
    "print('Accuracy = {:.5f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

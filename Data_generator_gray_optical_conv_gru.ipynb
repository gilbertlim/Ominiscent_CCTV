{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quality-tribune",
   "metadata": {},
   "source": [
    "# 1. VideoFrameGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-finish",
   "metadata": {},
   "source": [
    "#### Class(Fixed)\n",
    "- Normal : 150\n",
    "- Arson (+ Explosion) : 50 + 50 = 100\n",
    "- Assault (+ Abuse, Fighting) : 50 + 50 + 50 = 150\n",
    "- Burglary : 100\n",
    "\n",
    "#### Image Size(Fixed)\n",
    "- 128 X 128\n",
    "\n",
    "#### \\# of Frames(Fixed)\n",
    "- 64\n",
    "\n",
    "#### Data Split(Fixed)\n",
    "- 7 : 2 : 1\n",
    "\n",
    "#### Color Scale\n",
    "- **Gray** or RGB\n",
    "\n",
    "#### Frame Generator\n",
    "- Basic or Sliding or **OpticalFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unknown-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME='g_optical_conv_gru'\n",
    "\n",
    "SIZE = (128, 128)\n",
    "CHANNELS = 1 # Gray scale\n",
    "NBFRAME = 64 \n",
    "BS = 16\n",
    "SHUFFLE = True\n",
    "\n",
    "SPLIT_RATIO = (.2, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You didn't provide classes list or we were not able to discover them from your pattern.\n",
      "Please check if the path is OK, and if the glob pattern is correct.\n",
      "See https://docs.python.org/3/library/glob.html\n",
      "You didn't provide classes list or we were not able to discover them from your pattern.\n",
      "Please check if the path is OK, and if the glob pattern is correct.\n",
      "See https://docs.python.org/3/library/glob.html\n",
      "You didn't provide classes list or we were not able to discover them from your pattern.\n",
      "Please check if the path is OK, and if the glob pattern is correct.\n",
      "See https://docs.python.org/3/library/glob.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 0 classes for 0 files for train\n",
      "Total data: 0 classes for 0 files for validation\n",
      "Total data: 0 classes for 0 files for test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras\n",
    "\n",
    "import keras_video \n",
    "from keras_video import OpticalFlowGenerator\n",
    "\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('zip_integrate/*')]\n",
    "classes.sort()\n",
    "\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='zip_integrate/{classname}/*.mp4'\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "\n",
    "# Create sliding frame generator\n",
    "train = OpticalFlowGenerator(\n",
    "    method= keras_video.METHOD_ABS_DIFF, # optical flow method\n",
    "    classes=classes, # class list\n",
    "    glob_pattern=glob_pattern, # directory path\n",
    "    nb_frames=NBFRAME, # #of frames to return for each sequence\n",
    "    rescale=1/255., # normalization\n",
    "    split_val=SPLIT_RATIO[0], # split validation\n",
    "    split_test=SPLIT_RATIO[1], # split test\n",
    "    shuffle=SHUFFLE, # randomize\n",
    "    batch_size=BS, # batch size\n",
    "    target_shape=SIZE, # image size\n",
    "    nb_channel=CHANNELS, # gray scale\n",
    "    transformation=data_aug, # data augmentation\n",
    "    use_frame_cache=False)\n",
    "    \n",
    "valid = train.get_validation_generator()\n",
    "test = train.get_test_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virtual-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_video.utils\n",
    "\n",
    "# keras_video.utils.show_sample(test, index=0, random=False, row_width=10, row_height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-blues",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-rider",
   "metadata": {},
   "source": [
    "#### Conv2d + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naval-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "def build_convnet(shape=SIZE + (CHANNELS,)):\n",
    "    momentum = .9\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=shape, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    # flatten...\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "urban-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "\n",
    "def action_model(shape=(NBFRAME,) + SIZE + (CHANNELS,), nbout=len(classes)):\n",
    "    # Create our convnet with (128, 128, 1) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # add the convnet with (64, 128, 128, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "    \n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))\n",
    "    \n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-luther",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2b25ba8a9db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINSHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (64, 128, 128, 3)\n",
    "\n",
    "kmodel = action_model(INSHAPE, len(classes))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer,\n",
    "              'categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=3\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "\n",
    "callbacks = [keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "             keras.callbacks.ModelCheckpoint(\n",
    "             'chkp/weights_' + MODELNAME + '_.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "             verbose=1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-visitor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_model = model.fit(train,\n",
    "             validation_data=valid,\n",
    "             verbose=1,\n",
    "             epochs=EPOCHS,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(hist_model.history['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(epochs, hist_model.history['loss'])\n",
    "plt.plot(epochs, hist_model.history['val_loss'])\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(hist_model.history['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(epochs, hist_model.history['accuracy'])\n",
    "plt.plot(epochs, hist_model.history['val_accuracy'])\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "\n",
    "print('Loss = {:.5f}'.format(loss))\n",
    "print('Accuracy = {:.5f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'Models'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "final_model_name = '/' + MODELNAME + '.h5'\n",
    "\n",
    "model.save(save_dir + final_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lmn = load_model(save_dir + final_model_name)\n",
    "\n",
    "loss, accuracy = lmn.evaluate(test)\n",
    "\n",
    "print('Loss = {:.5f}'.format(loss))\n",
    "print('Accuracy = {:.5f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
